{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Trabalho AV3\n",
        "Marcelo de Souza Ribeiro\n",
        "Carolina de Souza Ribeiro"
      ],
      "metadata": {
        "id": "7eiurs1FFY3g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE13FmNiFWu1",
        "outputId": "a8fca204-70cd-467c-af56-40f329e48214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Bibliotecas importadas com sucesso!\n",
            "Vers√£o do pandas: 2.2.2\n",
            "Vers√£o do numpy: 2.0.2\n"
          ]
        }
      ],
      "source": [
        "# Imports principais\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import kagglehub\n",
        "\n",
        "# Configura√ß√µes de visualiza√ß√£o\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "plt.rcParams['font.size'] = 12\n",
        "sns.set_style(\"whitegrid\")\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configura√ß√µes do pandas\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "print(\"Bibliotecas importadas com sucesso!\")\n",
        "print(f\"Vers√£o do pandas: {pd.__version__}\")\n",
        "print(f\"Vers√£o do numpy: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download do dataset diretamente do Kaggle\n",
        "print(\"üîÑ Baixando dataset da Olist do Kaggle...\")\n",
        "\n",
        "try:\n",
        "    path = kagglehub.dataset_download(\"olistbr/brazilian-ecommerce\")\n",
        "    print(f\"Dataset baixado com sucesso!\")\n",
        "    print(f\"Caminho dos arquivos: {path}\")\n",
        "\n",
        "    # Listar todos os arquivos no diret√≥rio\n",
        "    files = os.listdir(path)\n",
        "    csv_files = [f for f in files if f.endswith(\".csv\")]\n",
        "\n",
        "    print(f\"\\n{len(csv_files)} arquivos CSV encontrados:\")\n",
        "    for i, file in enumerate(csv_files, 1):\n",
        "        file_path = os.path.join(path, file)\n",
        "        file_size = os.path.getsize(file_path) / (1024*1024)  # MB\n",
        "        print(f\"  {i}. {file} ({file_size:.2f} MB)\")\n",
        "\n",
        "    # Salvar o caminho para uso posterior\n",
        "    DATA_PATH = path\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erro no download: {e}\")\n",
        "    print(\"Verifique se voc√™ tem acesso ao Kaggle e as credenciais configuradas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTnghYD7FkE5",
        "outputId": "ef9c3b8e-fdb4-4a06-8832-a2788d2ec6d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Baixando dataset da Olist do Kaggle...\n",
            "‚úÖ Dataset baixado com sucesso!\n",
            "üìÅ Caminho dos arquivos: /kaggle/input/brazilian-ecommerce\n",
            "\n",
            "üìä 9 arquivos CSV encontrados:\n",
            "  1. olist_customers_dataset.csv (8.62 MB)\n",
            "  2. olist_sellers_dataset.csv (0.17 MB)\n",
            "  3. olist_order_reviews_dataset.csv (13.78 MB)\n",
            "  4. olist_order_items_dataset.csv (14.72 MB)\n",
            "  5. olist_products_dataset.csv (2.27 MB)\n",
            "  6. olist_geolocation_dataset.csv (58.44 MB)\n",
            "  7. product_category_name_translation.csv (0.00 MB)\n",
            "  8. olist_orders_dataset.csv (16.84 MB)\n",
            "  9. olist_order_payments_dataset.csv (5.51 MB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√£o auxiliar para carregar e inspecionar cada tabela\n",
        "def quick_inspect(filename, data_path):\n",
        "    \"\"\"Carrega um CSV e faz inspe√ß√£o b√°sica\"\"\"\n",
        "    filepath = os.path.join(data_path, filename)\n",
        "    df = pd.read_csv(filepath)\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"TABELA: {filename}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "    print(f\"Colunas: {list(df.columns)}\")\n",
        "    print(f\"Mem√≥ria: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Verificar se temos o caminho dos dados\n",
        "if 'DATA_PATH' in locals():\n",
        "    print(\"Fazendo inspe√ß√£o r√°pida de todos os arquivos...\")\n",
        "\n",
        "    # Dicion√°rio para armazenar os DataFrames\n",
        "    dfs = {}\n",
        "\n",
        "    # Inspecionar cada arquivo CSV\n",
        "    for csv_file in csv_files:\n",
        "        table_name = csv_file.replace('.csv', '').replace('olist_', '')\n",
        "        dfs[table_name] = quick_inspect(csv_file, DATA_PATH)\n",
        "\n",
        "    print(f\"\\nInspe√ß√£o inicial completa!\")\n",
        "    print(f\"Total de registros no dataset: {sum(df.shape[0] for df in dfs.values()):,}\")\n",
        "\n",
        "else:\n",
        "    print(\"Erro: DATA_PATH n√£o foi definido. Execute a c√©lula anterior primeiro.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39wqlbZlGVWr",
        "outputId": "0bbed2cb-eb37-45db-cacd-35b6b99bcc70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Fazendo inspe√ß√£o r√°pida de todos os arquivos...\n",
            "\n",
            "==================================================\n",
            "üìã TABELA: olist_customers_dataset.csv\n",
            "==================================================\n",
            "üìè Shape: (99441, 5)\n",
            "üîó Colunas: ['customer_id', 'customer_unique_id', 'customer_zip_code_prefix', 'customer_city', 'customer_state']\n",
            "üíæ Mem√≥ria: 29.62 MB\n",
            "\n",
            "==================================================\n",
            "üìã TABELA: olist_sellers_dataset.csv\n",
            "==================================================\n",
            "üìè Shape: (3095, 4)\n",
            "üîó Colunas: ['seller_id', 'seller_zip_code_prefix', 'seller_city', 'seller_state']\n",
            "üíæ Mem√≥ria: 0.66 MB\n",
            "\n",
            "==================================================\n",
            "üìã TABELA: olist_order_reviews_dataset.csv\n",
            "==================================================\n",
            "üìè Shape: (99224, 7)\n",
            "üîó Colunas: ['review_id', 'order_id', 'review_score', 'review_comment_title', 'review_comment_message', 'review_creation_date', 'review_answer_timestamp']\n",
            "üíæ Mem√≥ria: 42.75 MB\n",
            "\n",
            "==================================================\n",
            "üìã TABELA: olist_order_items_dataset.csv\n",
            "==================================================\n",
            "üìè Shape: (112650, 7)\n",
            "üîó Colunas: ['order_id', 'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date', 'price', 'freight_value']\n",
            "üíæ Mem√≥ria: 39.43 MB\n",
            "\n",
            "==================================================\n",
            "üìã TABELA: olist_products_dataset.csv\n",
            "==================================================\n",
            "üìè Shape: (32951, 9)\n",
            "üîó Colunas: ['product_id', 'product_category_name', 'product_name_lenght', 'product_description_lenght', 'product_photos_qty', 'product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm']\n",
            "üíæ Mem√≥ria: 6.79 MB\n",
            "\n",
            "==================================================\n",
            "üìã TABELA: olist_geolocation_dataset.csv\n",
            "==================================================\n",
            "üìè Shape: (1000163, 5)\n",
            "üîó Colunas: ['geolocation_zip_code_prefix', 'geolocation_lat', 'geolocation_lng', 'geolocation_city', 'geolocation_state']\n",
            "üíæ Mem√≥ria: 145.20 MB\n",
            "\n",
            "==================================================\n",
            "üìã TABELA: product_category_name_translation.csv\n",
            "==================================================\n",
            "üìè Shape: (71, 2)\n",
            "üîó Colunas: ['product_category_name', 'product_category_name_english']\n",
            "üíæ Mem√≥ria: 0.01 MB\n",
            "\n",
            "==================================================\n",
            "üìã TABELA: olist_orders_dataset.csv\n",
            "==================================================\n",
            "üìè Shape: (99441, 8)\n",
            "üîó Colunas: ['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
            "üíæ Mem√≥ria: 58.97 MB\n",
            "\n",
            "==================================================\n",
            "üìã TABELA: olist_order_payments_dataset.csv\n",
            "==================================================\n",
            "üìè Shape: (103886, 5)\n",
            "üîó Colunas: ['order_id', 'payment_sequential', 'payment_type', 'payment_installments', 'payment_value']\n",
            "üíæ Mem√≥ria: 17.81 MB\n",
            "\n",
            "‚úÖ Inspe√ß√£o inicial completa!\n",
            "üìä Total de registros no dataset: 1,550,922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## An√°lise Explorat√≥ria das Tabelas Principais\n",
        "\n",
        "Agora que temos uma vis√£o geral do dataset, vamos analisar em detalhes as tabelas que ser√£o centrais para nossos problemas de machine learning. Come√ßaremos pela tabela de pedidos (orders), que funciona como a espinha dorsal do dataset, e depois examinaremos as tabelas relacionadas.\n",
        "\n",
        "O objetivo desta etapa √© entender:\n",
        "- A estrutura e qualidade dos dados em cada tabela\n",
        "- Distribui√ß√µes das vari√°veis principais\n",
        "- Presen√ßa de valores ausentes ou inconsist√™ncias"
      ],
      "metadata": {
        "id": "y-neDk2YHub2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An√°lise detalhada da tabela principal de pedidos\n",
        "print(\"AN√ÅLISE DA TABELA ORDERS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "orders = dfs['orders_dataset']\n",
        "print(f\"Dimens√µes: {orders.shape[0]} linhas x {orders.shape[1]} colunas\")\n",
        "print(f\"Colunas dispon√≠veis: {orders.columns.tolist()}\")\n",
        "\n",
        "# Verificar tipos de dados e valores ausentes\n",
        "print(\"\\nInforma√ß√µes sobre tipos de dados e valores ausentes:\")\n",
        "for col in orders.columns:\n",
        "    dtype = orders[col].dtype\n",
        "    unique_count = orders[col].nunique()\n",
        "    null_count = orders[col].isnull().sum()\n",
        "    null_pct = (null_count / len(orders)) * 100\n",
        "    print(f\"{col:30} | {str(dtype):15} | {unique_count:8,} √∫nicos | {null_count:6,} nulos ({null_pct:5.1f}%)\")\n",
        "\n",
        "# Analisar distribui√ß√£o dos status dos pedidos\n",
        "print(f\"\\nDistribui√ß√£o dos status dos pedidos:\")\n",
        "status_counts = orders['order_status'].value_counts()\n",
        "for status, count in status_counts.items():\n",
        "    pct = (count / len(orders)) * 100\n",
        "    print(f\"{status:20} | {count:6,} ({pct:5.1f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp58-pVZHvoA",
        "outputId": "2dab8151-7220-457f-f036-44d810becd09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AN√ÅLISE DA TABELA ORDERS\n",
            "==================================================\n",
            "Dimens√µes: 99441 linhas x 8 colunas\n",
            "Colunas dispon√≠veis: ['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
            "\n",
            "Informa√ß√µes sobre tipos de dados e valores ausentes:\n",
            "order_id                       | object          |   99,441 √∫nicos |      0 nulos (  0.0%)\n",
            "customer_id                    | object          |   99,441 √∫nicos |      0 nulos (  0.0%)\n",
            "order_status                   | object          |        8 √∫nicos |      0 nulos (  0.0%)\n",
            "order_purchase_timestamp       | object          |   98,875 √∫nicos |      0 nulos (  0.0%)\n",
            "order_approved_at              | object          |   90,733 √∫nicos |    160 nulos (  0.2%)\n",
            "order_delivered_carrier_date   | object          |   81,018 √∫nicos |  1,783 nulos (  1.8%)\n",
            "order_delivered_customer_date  | object          |   95,664 √∫nicos |  2,965 nulos (  3.0%)\n",
            "order_estimated_delivery_date  | object          |      459 √∫nicos |      0 nulos (  0.0%)\n",
            "\n",
            "Distribui√ß√£o dos status dos pedidos:\n",
            "delivered            | 96,478 ( 97.0%)\n",
            "shipped              |  1,107 (  1.1%)\n",
            "canceled             |    625 (  0.6%)\n",
            "unavailable          |    609 (  0.6%)\n",
            "invoiced             |    314 (  0.3%)\n",
            "processing           |    301 (  0.3%)\n",
            "created              |      5 (  0.0%)\n",
            "approved             |      2 (  0.0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## An√°lise das Tabelas Complementares\n",
        "\n",
        "Vamos examinar as tabelas que cont√™m informa√ß√µes espec√≠ficas sobre diferentes aspectos dos pedidos: itens comprados, avalia√ß√µes dos clientes e dados de pagamento. Essas tabelas ser√£o fundamentais para a constru√ß√£o de features para nossos modelos."
      ],
      "metadata": {
        "id": "-UWV-tvsHyzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An√°lise da tabela de itens dos pedidos\n",
        "print(\"AN√ÅLISE DA TABELA ORDER_ITEMS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "items = dfs['order_items_dataset']\n",
        "print(f\"Dimens√µes: {items.shape}\")\n",
        "\n",
        "# Estat√≠sticas descritivas dos valores monet√°rios\n",
        "print(\"\\nEstat√≠sticas dos valores de pre√ßo e frete:\")\n",
        "numeric_cols = ['price', 'freight_value']\n",
        "print(items[numeric_cols].describe())\n",
        "\n",
        "# An√°lise da tabela de reviews\n",
        "print(\"\\n\\nAN√ÅLISE DA TABELA REVIEWS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "reviews = dfs['order_reviews_dataset']\n",
        "print(f\"Dimens√µes: {reviews.shape}\")\n",
        "\n",
        "# Distribui√ß√£o das notas de avalia√ß√£o\n",
        "print(\"\\nDistribui√ß√£o das notas de avalia√ß√£o:\")\n",
        "score_dist = reviews['review_score'].value_counts().sort_index()\n",
        "for score, count in score_dist.items():\n",
        "    pct = (count / len(reviews)) * 100\n",
        "    print(f\"Nota {score}: {count:6,} avalia√ß√µes ({pct:5.1f}%)\")\n",
        "\n",
        "# Verificar reviews com coment√°rios\n",
        "has_title = reviews['review_comment_title'].notna().sum()\n",
        "has_message = reviews['review_comment_message'].notna().sum()\n",
        "print(f\"\\nReviews com t√≠tulo: {has_title:,} ({has_title/len(reviews)*100:.1f}%)\")\n",
        "print(f\"Reviews com mensagem: {has_message:,} ({has_message/len(reviews)*100:.1f}%)\")\n",
        "\n",
        "# An√°lise da tabela de pagamentos\n",
        "print(\"\\n\\nAN√ÅLISE DA TABELA PAYMENTS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "payments = dfs['order_payments_dataset']\n",
        "print(f\"Dimens√µes: {payments.shape}\")\n",
        "\n",
        "# Tipos de pagamento\n",
        "print(\"\\nDistribui√ß√£o dos tipos de pagamento:\")\n",
        "payment_types = payments['payment_type'].value_counts()\n",
        "for ptype, count in payment_types.items():\n",
        "    pct = (count / len(payments)) * 100\n",
        "    print(f\"{ptype:15} | {count:6,} ({pct:5.1f}%)\")\n",
        "\n",
        "# Estat√≠sticas dos valores de pagamento\n",
        "print(f\"\\nEstat√≠sticas dos valores de pagamento:\")\n",
        "print(payments['payment_value'].describe())\n",
        "\n",
        "# An√°lise das parcelas\n",
        "print(f\"\\nDistribui√ß√£o do n√∫mero de parcelas:\")\n",
        "installments_dist = payments['payment_installments'].value_counts().head(10)\n",
        "for inst, count in installments_dist.items():\n",
        "    pct = (count / len(payments)) * 100\n",
        "    print(f\"{inst:2.0f} parcelas: {count:6,} ({pct:5.1f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1hMfLY3H0wi",
        "outputId": "d7686406-6bac-4d2f-a458-4a0a36f0f8a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AN√ÅLISE DA TABELA ORDER_ITEMS\n",
            "==================================================\n",
            "Dimens√µes: (112650, 7)\n",
            "\n",
            "Estat√≠sticas dos valores de pre√ßo e frete:\n",
            "               price  freight_value\n",
            "count  112650.000000  112650.000000\n",
            "mean      120.653739      19.990320\n",
            "std       183.633928      15.806405\n",
            "min         0.850000       0.000000\n",
            "25%        39.900000      13.080000\n",
            "50%        74.990000      16.260000\n",
            "75%       134.900000      21.150000\n",
            "max      6735.000000     409.680000\n",
            "\n",
            "\n",
            "AN√ÅLISE DA TABELA REVIEWS\n",
            "==================================================\n",
            "Dimens√µes: (99224, 7)\n",
            "\n",
            "Distribui√ß√£o das notas de avalia√ß√£o:\n",
            "Nota 1: 11,424 avalia√ß√µes ( 11.5%)\n",
            "Nota 2:  3,151 avalia√ß√µes (  3.2%)\n",
            "Nota 3:  8,179 avalia√ß√µes (  8.2%)\n",
            "Nota 4: 19,142 avalia√ß√µes ( 19.3%)\n",
            "Nota 5: 57,328 avalia√ß√µes ( 57.8%)\n",
            "\n",
            "Reviews com t√≠tulo: 11,568 (11.7%)\n",
            "Reviews com mensagem: 40,977 (41.3%)\n",
            "\n",
            "\n",
            "AN√ÅLISE DA TABELA PAYMENTS\n",
            "==================================================\n",
            "Dimens√µes: (103886, 5)\n",
            "\n",
            "Distribui√ß√£o dos tipos de pagamento:\n",
            "credit_card     | 76,795 ( 73.9%)\n",
            "boleto          | 19,784 ( 19.0%)\n",
            "voucher         |  5,775 (  5.6%)\n",
            "debit_card      |  1,529 (  1.5%)\n",
            "not_defined     |      3 (  0.0%)\n",
            "\n",
            "Estat√≠sticas dos valores de pagamento:\n",
            "count    103886.000000\n",
            "mean        154.100380\n",
            "std         217.494064\n",
            "min           0.000000\n",
            "25%          56.790000\n",
            "50%         100.000000\n",
            "75%         171.837500\n",
            "max       13664.080000\n",
            "Name: payment_value, dtype: float64\n",
            "\n",
            "Distribui√ß√£o do n√∫mero de parcelas:\n",
            " 1 parcelas: 52,546 ( 50.6%)\n",
            " 2 parcelas: 12,413 ( 11.9%)\n",
            " 3 parcelas: 10,461 ( 10.1%)\n",
            " 4 parcelas:  7,098 (  6.8%)\n",
            "10 parcelas:  5,328 (  5.1%)\n",
            " 5 parcelas:  5,239 (  5.0%)\n",
            " 8 parcelas:  4,268 (  4.1%)\n",
            " 6 parcelas:  3,920 (  3.8%)\n",
            " 7 parcelas:  1,626 (  1.6%)\n",
            " 9 parcelas:    644 (  0.6%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verifica√ß√£o da Integridade dos Relacionamentos\n",
        "\n",
        "Antes de prosseguir com a defini√ß√£o dos problemas de machine learning, √© crucial verificar como as tabelas se relacionam e identificar poss√≠veis inconsist√™ncias nos dados. Vamos analisar a cobertura dos relacionamentos e identificar padr√µes que podem ser relevantes para nossos modelos."
      ],
      "metadata": {
        "id": "_Ec-q2fvH22O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifica√ß√£o dos relacionamentos entre tabelas atrav√©s de order_id\n",
        "print(\"VERIFICA√á√ÉO DE RELACIONAMENTOS ENTRE TABELAS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Coletar conjuntos de order_ids de cada tabela\n",
        "orders_ids = set(orders['order_id'])\n",
        "items_ids = set(items['order_id'])\n",
        "reviews_ids = set(reviews['order_id'])\n",
        "payments_ids = set(payments['order_id'])\n",
        "\n",
        "print(\"Contagem de order_ids √∫nicos por tabela:\")\n",
        "print(f\"Orders:   {len(orders_ids):6,}\")\n",
        "print(f\"Items:    {len(items_ids):6,}\")\n",
        "print(f\"Reviews:  {len(reviews_ids):6,}\")\n",
        "print(f\"Payments: {len(payments_ids):6,}\")\n",
        "\n",
        "# Verificar intersec√ß√µes\n",
        "print(\"\\nIntersec√ß√µes entre tabelas:\")\n",
        "orders_with_items = len(orders_ids & items_ids)\n",
        "orders_with_reviews = len(orders_ids & reviews_ids)\n",
        "orders_with_payments = len(orders_ids & payments_ids)\n",
        "\n",
        "print(f\"Orders que t√™m itens:     {orders_with_items:6,} ({orders_with_items/len(orders_ids)*100:5.1f}%)\")\n",
        "print(f\"Orders que t√™m reviews:   {orders_with_reviews:6,} ({orders_with_reviews/len(orders_ids)*100:5.1f}%)\")\n",
        "print(f\"Orders que t√™m payments:  {orders_with_payments:6,} ({orders_with_payments/len(orders_ids)*100:5.1f}%)\")\n",
        "\n",
        "# Identificar orders sem reviews (pode ser um problema interessante)\n",
        "orders_sem_review = orders_ids - reviews_ids\n",
        "pct_sem_review = len(orders_sem_review) / len(orders_ids) * 100\n",
        "print(f\"\\nOrders SEM review: {len(orders_sem_review):,} ({pct_sem_review:.1f}%)\")\n",
        "\n",
        "# Analisar quantos itens por pedido\n",
        "items_por_pedido = items.groupby('order_id').size()\n",
        "print(f\"\\nDistribui√ß√£o de itens por pedido:\")\n",
        "print(items_por_pedido.describe())\n",
        "\n",
        "# Verificar se h√° pedidos com m√∫ltiplos pagamentos\n",
        "payments_por_pedido = payments.groupby('order_id').size()\n",
        "pedidos_multiplos_pagamentos = (payments_por_pedido > 1).sum()\n",
        "print(f\"\\nPedidos com m√∫ltiplos pagamentos: {pedidos_multiplos_pagamentos:,}\")\n",
        "if pedidos_multiplos_pagamentos > 0:\n",
        "    print(\"Distribui√ß√£o de pagamentos por pedido:\")\n",
        "    print(payments_por_pedido.value_counts().head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYC_gsl5H4ky",
        "outputId": "35519176-44ad-467f-d2de-1f98c31ac1bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VERIFICA√á√ÉO DE RELACIONAMENTOS ENTRE TABELAS\n",
            "============================================================\n",
            "Contagem de order_ids √∫nicos por tabela:\n",
            "Orders:   99,441\n",
            "Items:    98,666\n",
            "Reviews:  98,673\n",
            "Payments: 99,440\n",
            "\n",
            "Intersec√ß√µes entre tabelas:\n",
            "Orders que t√™m itens:     98,666 ( 99.2%)\n",
            "Orders que t√™m reviews:   98,673 ( 99.2%)\n",
            "Orders que t√™m payments:  99,440 (100.0%)\n",
            "\n",
            "Orders SEM review: 768 (0.8%)\n",
            "\n",
            "Distribui√ß√£o de itens por pedido:\n",
            "count    98666.000000\n",
            "mean         1.141731\n",
            "std          0.538452\n",
            "min          1.000000\n",
            "25%          1.000000\n",
            "50%          1.000000\n",
            "75%          1.000000\n",
            "max         21.000000\n",
            "dtype: float64\n",
            "\n",
            "Pedidos com m√∫ltiplos pagamentos: 2,961\n",
            "Distribui√ß√£o de pagamentos por pedido:\n",
            "1     96479\n",
            "2      2382\n",
            "3       301\n",
            "4       108\n",
            "5        52\n",
            "6        36\n",
            "7        28\n",
            "8        11\n",
            "9         9\n",
            "11        8\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defini√ß√£o dos Problemas de Machine Learning\n",
        "\n",
        "Com base na an√°lise explorat√≥ria, definimos dois problemas complementares que oferecem valor comercial e desafio t√©cnico adequado ao escopo do projeto.\n",
        "\n",
        "### Problema 1: Aprendizado Supervisionado (Classifica√ß√£o)\n",
        "**Objetivo**: Predizer a nota de avalia√ß√£o (review_score) que um cliente dar√° a um pedido\n",
        "\n",
        "**Justificativa**:\n",
        "- Permite √† Olist antecipar satisfa√ß√£o do cliente\n",
        "- Identificar pedidos com risco de baixa avalia√ß√£o\n",
        "- Otimizar estrat√©gias de atendimento pr√©-entrega\n",
        "\n",
        "**Target**: review_score (vari√°vel categ√≥rica ordinal: 1, 2, 3, 4, 5)\n",
        "**Tipo**: Classifica√ß√£o multi-classe com 5 categorias\n",
        "**Desafio**: Distribui√ß√£o desbalanceada (57.8% classe 5, 11.5% classe 1)\n",
        "\n",
        "### Problema 2: Aprendizado N√£o Supervisionado (Clustering)\n",
        "**Objetivo**: Segmentar pedidos por comportamento de compra para identificar perfis distintos de consumo\n",
        "\n",
        "**Justificativa**:\n",
        "- Personaliza√ß√£o de estrat√©gias de marketing\n",
        "- Otimiza√ß√£o de log√≠stica por perfil\n",
        "- Identifica√ß√£o de oportunidades de cross-selling\n",
        "\n",
        "**Abordagem**: Clustering baseado em caracter√≠sticas de comportamento de compra\n",
        "**Algoritmos**: K-Means, DBSCAN, Gaussian Mixture Models"
      ],
      "metadata": {
        "id": "1ZQGFdqgOSdA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analise dos Dados para Feature Engineering"
      ],
      "metadata": {
        "id": "A_4kLAyedTSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar quais DataFrames est√£o carregados e suas dimens√µes\n",
        "print(\"=== ESTADO ATUAL DOS DATAFRAMES ===\")\n",
        "\n",
        "# Acessar os dataframes do dicion√°rio dfs\n",
        "orders = dfs['orders_dataset']\n",
        "items = dfs['order_items_dataset']\n",
        "payments = dfs['order_payments_dataset']\n",
        "reviews = dfs['order_reviews_dataset']\n",
        "customers = dfs['customers_dataset']\n",
        "products = dfs['products_dataset']\n",
        "sellers = dfs['sellers_dataset']\n",
        "\n",
        "dataframes = {\n",
        "    'orders': orders,\n",
        "    'items': items,\n",
        "    'payments': payments,\n",
        "    'reviews': reviews,\n",
        "    'customers': customers,\n",
        "    'products': products,\n",
        "    'sellers': sellers\n",
        "}\n",
        "\n",
        "for name, df in dataframes.items():\n",
        "    print(f\"{name}: {df.shape}\")\n",
        "    print(f\"  Colunas: {df.columns.tolist()[:5]}...\")  # Primeiras 5 colunas\n",
        "    print(f\"  Valores nulos: {df.isnull().sum().sum()}\")\n",
        "    print()\n",
        "\n",
        "print(\"DataFrames organizados com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ2P7y9xdXdn",
        "outputId": "8f529e49-d337-4e32-cea5-59df7cb32cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ESTADO ATUAL DOS DATAFRAMES ===\n",
            "orders: (99441, 8)\n",
            "  Colunas: ['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', 'order_approved_at']...\n",
            "  Valores nulos: 4908\n",
            "\n",
            "items: (112650, 7)\n",
            "  Colunas: ['order_id', 'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date']...\n",
            "  Valores nulos: 0\n",
            "\n",
            "payments: (103886, 5)\n",
            "  Colunas: ['order_id', 'payment_sequential', 'payment_type', 'payment_installments', 'payment_value']...\n",
            "  Valores nulos: 0\n",
            "\n",
            "reviews: (99224, 7)\n",
            "  Colunas: ['review_id', 'order_id', 'review_score', 'review_comment_title', 'review_comment_message']...\n",
            "  Valores nulos: 145903\n",
            "\n",
            "customers: (99441, 5)\n",
            "  Colunas: ['customer_id', 'customer_unique_id', 'customer_zip_code_prefix', 'customer_city', 'customer_state']...\n",
            "  Valores nulos: 0\n",
            "\n",
            "products: (32951, 9)\n",
            "  Colunas: ['product_id', 'product_category_name', 'product_name_lenght', 'product_description_lenght', 'product_photos_qty']...\n",
            "  Valores nulos: 2448\n",
            "\n",
            "sellers: (3095, 4)\n",
            "  Colunas: ['seller_id', 'seller_zip_code_prefix', 'seller_city', 'seller_state']...\n",
            "  Valores nulos: 0\n",
            "\n",
            "DataFrames organizados com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converter colunas de data para datetime\n",
        "print(\"=== PREPARA√á√ÉO DAS COLUNAS DE DATA ===\")\n",
        "\n",
        "# Colunas de data no dataset orders\n",
        "date_columns = [\n",
        "    'order_purchase_timestamp',\n",
        "    'order_approved_at',\n",
        "    'order_delivered_carrier_date',\n",
        "    'order_delivered_customer_date',\n",
        "    'order_estimated_delivery_date'\n",
        "]\n",
        "\n",
        "for col in date_columns:\n",
        "    if col in orders.columns:\n",
        "        orders[col] = pd.to_datetime(orders[col], errors='coerce')\n",
        "        print(f\"‚úì {col} convertida para datetime\")\n",
        "\n",
        "# Verificar se h√° outros datasets com colunas de data\n",
        "if 'review_creation_date' in reviews.columns:\n",
        "    reviews['review_creation_date'] = pd.to_datetime(reviews['review_creation_date'], errors='coerce')\n",
        "    print(\"‚úì review_creation_date convertida para datetime\")\n",
        "\n",
        "if 'review_answer_timestamp' in reviews.columns:\n",
        "    reviews['review_answer_timestamp'] = pd.to_datetime(reviews['review_answer_timestamp'], errors='coerce')\n",
        "    print(\"‚úì review_answer_timestamp convertida para datetime\")\n",
        "\n",
        "print(\"\\nDatasets preparados para feature engineering!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZLgXEjkdaNm",
        "outputId": "2c58e1a4-300a-4e0d-868e-39da352e14ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PREPARA√á√ÉO DAS COLUNAS DE DATA ===\n",
            "‚úì order_purchase_timestamp convertida para datetime\n",
            "‚úì order_approved_at convertida para datetime\n",
            "‚úì order_delivered_carrier_date convertida para datetime\n",
            "‚úì order_delivered_customer_date convertida para datetime\n",
            "‚úì order_estimated_delivery_date convertida para datetime\n",
            "‚úì review_creation_date convertida para datetime\n",
            "‚úì review_answer_timestamp convertida para datetime\n",
            "\n",
            "Datasets preparados para feature engineering!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CRIANDO FEATURES TEMPORAIS ESSENCIAIS ===\n",
        "print(\"Criando features temporais b√°sicas...\")\n",
        "\n",
        "# Calcular dias para entrega\n",
        "orders_clean['dias_para_entrega'] = (\n",
        "    orders_clean['order_delivered_customer_date'] -\n",
        "    orders_clean['order_purchase_timestamp']\n",
        ").dt.days\n",
        "\n",
        "# Calcular dias de atraso\n",
        "orders_clean['dias_atraso'] = (\n",
        "    orders_clean['order_delivered_customer_date'] -\n",
        "    orders_clean['order_estimated_delivery_date']\n",
        ").dt.days\n",
        "\n",
        "print(f\"Features criadas:\")\n",
        "print(f\"  dias_para_entrega: {orders_clean['dias_para_entrega'].notna().sum()} valores\")\n",
        "print(f\"  dias_atraso: {orders_clean['dias_atraso'].notna().sum()} valores\")"
      ],
      "metadata": {
        "id": "BsUHMsnqpXRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === AN√ÅLISE DE QUALIDADE DOS DADOS ===\n",
        "print(\"=== AN√ÅLISE DE QUALIDADE E PROBLEMAS NOS DADOS ===\")\n",
        "\n",
        "# 1. AN√ÅLISE DA TABELA ORDERS\n",
        "print(\"1. PROBLEMAS NA TABELA ORDERS:\")\n",
        "print(f\"   Total de pedidos: {len(orders):,}\")\n",
        "\n",
        "# Status dos pedidos\n",
        "status_counts = orders['order_status'].value_counts()\n",
        "print(f\"\\n   Distribui√ß√£o de status:\")\n",
        "for status, count in status_counts.items():\n",
        "    pct = count/len(orders)*100\n",
        "    print(f\"     {status}: {count:,} ({pct:.1f}%)\")\n",
        "\n",
        "# Pedidos sem data de entrega\n",
        "sem_entrega = orders['order_delivered_customer_date'].isnull().sum()\n",
        "print(f\"\\n   Pedidos SEM data de entrega: {sem_entrega:,} ({sem_entrega/len(orders)*100:.1f}%)\")\n",
        "\n",
        "# Verificar status dos pedidos sem entrega\n",
        "print(\"   Status dos pedidos sem data de entrega:\")\n",
        "sem_entrega_status = orders[orders['order_delivered_customer_date'].isnull()]['order_status'].value_counts()\n",
        "for status, count in sem_entrega_status.items():\n",
        "    print(f\"     {status}: {count:,}\")\n",
        "\n",
        "# 2. AN√ÅLISE DE OUTLIERS NAS FEATURES TEMPORAIS\n",
        "print(f\"\\n2. AN√ÅLISE DE OUTLIERS TEMPORAIS:\")\n",
        "delivered_orders = orders.dropna(subset=['order_delivered_customer_date'])\n",
        "print(f\"   Pedidos entregues para an√°lise: {len(delivered_orders):,}\")\n",
        "\n",
        "# Outliers de tempo de entrega\n",
        "q99_entrega = delivered_orders['dias_para_entrega'].quantile(0.99)\n",
        "outliers_entrega = (delivered_orders['dias_para_entrega'] > q99_entrega).sum()\n",
        "print(f\"   Outliers tempo entrega (>P99={q99_entrega:.0f} dias): {outliers_entrega:,}\")\n",
        "\n",
        "# Outliers de atraso\n",
        "atraso_extremo = delivered_orders['dias_atraso'] > 30  # 30 dias de atraso\n",
        "outliers_atraso = atraso_extremo.sum()\n",
        "print(f\"   Pedidos com atraso >30 dias: {outliers_atraso:,}\")\n",
        "\n",
        "# 3. COBERTURA DE REVIEWS\n",
        "print(f\"\\n3. COBERTURA DE REVIEWS:\")\n",
        "orders_com_review = orders['order_id'].isin(reviews['order_id']).sum()\n",
        "print(f\"   Pedidos com review: {orders_com_review:,} ({orders_com_review/len(orders)*100:.1f}%)\")\n",
        "print(f\"   Pedidos SEM review: {len(orders) - orders_com_review:,}\")\n",
        "\n",
        "# 4. VERIFICAR RELACIONAMENTOS\n",
        "print(f\"\\n4. VERIFICA√á√ÉO DE RELACIONAMENTOS:\")\n",
        "print(f\"   Orders √∫nicos: {orders['order_id'].nunique():,}\")\n",
        "print(f\"   Reviews √∫nicos: {reviews['order_id'].nunique():,}\")\n",
        "print(f\"   Items √∫nicos: {items['order_id'].nunique():,}\")\n",
        "print(f\"   Payments √∫nicos: {payments['order_id'].nunique():,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbsUMdyjf7NW",
        "outputId": "3c6f909f-0497-4971-df93-a92a485a61b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== AN√ÅLISE DE QUALIDADE E PROBLEMAS NOS DADOS ===\n",
            "1. PROBLEMAS NA TABELA ORDERS:\n",
            "   Total de pedidos: 99,441\n",
            "\n",
            "   Distribui√ß√£o de status:\n",
            "     delivered: 96,478 (97.0%)\n",
            "     shipped: 1,107 (1.1%)\n",
            "     canceled: 625 (0.6%)\n",
            "     unavailable: 609 (0.6%)\n",
            "     invoiced: 314 (0.3%)\n",
            "     processing: 301 (0.3%)\n",
            "     created: 5 (0.0%)\n",
            "     approved: 2 (0.0%)\n",
            "\n",
            "   Pedidos SEM data de entrega: 2,965 (3.0%)\n",
            "   Status dos pedidos sem data de entrega:\n",
            "     shipped: 1,107\n",
            "     canceled: 619\n",
            "     unavailable: 609\n",
            "     invoiced: 314\n",
            "     processing: 301\n",
            "     delivered: 8\n",
            "     created: 5\n",
            "     approved: 2\n",
            "\n",
            "2. AN√ÅLISE DE OUTLIERS TEMPORAIS:\n",
            "   Pedidos entregues para an√°lise: 96,476\n",
            "   Outliers tempo entrega (>P99=46 dias): 880\n",
            "   Pedidos com atraso >30 dias: 345\n",
            "\n",
            "3. COBERTURA DE REVIEWS:\n",
            "   Pedidos com review: 98,673 (99.2%)\n",
            "   Pedidos SEM review: 768\n",
            "\n",
            "4. VERIFICA√á√ÉO DE RELACIONAMENTOS:\n",
            "   Orders √∫nicos: 99,441\n",
            "   Reviews √∫nicos: 98,673\n",
            "   Items √∫nicos: 98,666\n",
            "   Payments √∫nicos: 99,440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === ESTRAT√âGIA DE LIMPEZA DOS DADOS ===\n",
        "print(\"=== DEFININDO ESTRAT√âGIA DE LIMPEZA ===\")\n",
        "\n",
        "print(\"PROBLEMAS IDENTIFICADOS E SOLU√á√ïES:\")\n",
        "print(\"1. 3% dos pedidos n√£o t√™m data de entrega (principalmente shipped/canceled)\")\n",
        "print(\"   ‚Üí Filtrar apenas pedidos 'delivered' para an√°lise\")\n",
        "print(\"2. 880 outliers com tempo entrega >46 dias\")\n",
        "print(\"   ‚Üí Manter, mas criar flag para an√°lise\")\n",
        "print(\"3. 0.8% dos pedidos sem review\")\n",
        "print(\"   ‚Üí Para o problema supervisionado, usar apenas com review\")\n",
        "print(\"4. Cobertura boa de items e payments\")\n",
        "\n",
        "print(\"\\n=== IMPLEMENTANDO LIMPEZA ===\")\n",
        "\n",
        "# PASSO 1: Filtrar apenas pedidos delivered\n",
        "print(\"1. Filtrando pedidos delivered...\")\n",
        "orders_clean = orders[orders['order_status'] == 'delivered'].copy()\n",
        "print(f\"   Antes: {len(orders):,} | Depois: {len(orders_clean):,}\")\n",
        "\n",
        "# PASSO 2: Remover pedidos sem data de entrega (mesmo sendo delivered)\n",
        "print(\"2. Removendo pedidos delivered sem data de entrega...\")\n",
        "orders_clean = orders_clean.dropna(subset=['order_delivered_customer_date'])\n",
        "print(f\"   Pedidos finais: {len(orders_clean):,}\")\n",
        "\n",
        "# PASSO 3: Criar flags para outliers (n√£o remover)\n",
        "print(\"3. Criando flags de qualidade...\")\n",
        "orders_clean['outlier_tempo_entrega'] = (orders_clean['dias_para_entrega'] > 46).astype(int)\n",
        "orders_clean['atraso_extremo'] = (orders_clean['dias_atraso'] > 30).astype(int)\n",
        "orders_clean['entrega_muito_rapida'] = (orders_clean['dias_para_entrega'] < 1).astype(int)\n",
        "\n",
        "# PASSO 4: Filtrar tabelas relacionadas para manter consist√™ncia\n",
        "print(\"4. Filtrando tabelas relacionadas...\")\n",
        "order_ids_clean = set(orders_clean['order_id'])\n",
        "\n",
        "# Filtrar reviews, items, payments\n",
        "reviews_clean = reviews[reviews['order_id'].isin(order_ids_clean)].copy()\n",
        "items_clean = items[items['order_id'].isin(order_ids_clean)].copy()\n",
        "payments_clean = payments[payments['order_id'].isin(order_ids_clean)].copy()\n",
        "\n",
        "print(f\"   Reviews: {len(reviews):,} ‚Üí {len(reviews_clean):,}\")\n",
        "print(f\"   Items: {len(items):,} ‚Üí {len(items_clean):,}\")\n",
        "print(f\"   Payments: {len(payments):,} ‚Üí {len(payments_clean):,}\")\n",
        "\n",
        "# PASSO 5: Verificar cobertura final\n",
        "print(\"5. Verifica√ß√£o final de cobertura...\")\n",
        "orders_com_review = orders_clean['order_id'].isin(reviews_clean['order_id']).sum()\n",
        "orders_com_items = orders_clean['order_id'].isin(items_clean['order_id']).sum()\n",
        "orders_com_payments = orders_clean['order_id'].isin(payments_clean['order_id']).sum()\n",
        "\n",
        "print(f\"   Orders com review: {orders_com_review:,} ({orders_com_review/len(orders_clean)*100:.1f}%)\")\n",
        "print(f\"   Orders com items: {orders_com_items:,} ({orders_com_items/len(orders_clean)*100:.1f}%)\")\n",
        "print(f\"   Orders com payments: {orders_com_payments:,} ({orders_com_payments/len(orders_clean)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\n DADOS LIMPOS PRONTOS PARA FEATURE ENGINEERING!\")\n",
        "print(f\"Dataset final: {len(orders_clean):,} pedidos delivered com dados completos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st-pBbUPgOCW",
        "outputId": "c937fe1a-83f0-4f95-ba52-26c937f1a332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== DEFININDO ESTRAT√âGIA DE LIMPEZA ===\n",
            "PROBLEMAS IDENTIFICADOS E SOLU√á√ïES:\n",
            "1. 3% dos pedidos n√£o t√™m data de entrega (principalmente shipped/canceled)\n",
            "   ‚Üí Filtrar apenas pedidos 'delivered' para an√°lise\n",
            "2. 880 outliers com tempo entrega >46 dias\n",
            "   ‚Üí Manter, mas criar flag para an√°lise\n",
            "3. 0.8% dos pedidos sem review\n",
            "   ‚Üí Para o problema supervisionado, usar apenas com review\n",
            "4. Cobertura boa de items e payments\n",
            "\n",
            "=== IMPLEMENTANDO LIMPEZA ===\n",
            "1. Filtrando pedidos delivered...\n",
            "   Antes: 99,441 | Depois: 96,478\n",
            "2. Removendo pedidos delivered sem data de entrega...\n",
            "   Pedidos finais: 96,470\n",
            "3. Criando flags de qualidade...\n",
            "4. Filtrando tabelas relacionadas...\n",
            "   Reviews: 99,224 ‚Üí 96,353\n",
            "   Items: 112,650 ‚Üí 110,189\n",
            "   Payments: 103,886 ‚Üí 100,748\n",
            "5. Verifica√ß√£o final de cobertura...\n",
            "   Orders com review: 95,824 (99.3%)\n",
            "   Orders com items: 96,470 (100.0%)\n",
            "   Orders com payments: 96,469 (100.0%)\n",
            "\n",
            " DADOS LIMPOS PRONTOS PARA FEATURE ENGINEERING!\n",
            "Dataset final: 96,470 pedidos delivered com dados completos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === VALIDA√á√ÉO FINAL DOS DADOS LIMPOS ===\n",
        "print(\"=== VALIDA√á√ÉO FINAL DOS DADOS LIMPOS ===\")\n",
        "\n",
        "# 1. Verificar se todas as vari√°veis temporais s√£o v√°lidas agora\n",
        "print(\"1. QUALIDADE DAS FEATURES TEMPORAIS:\")\n",
        "print(f\"   dias_para_entrega - valores nulos: {orders_clean['dias_para_entrega'].isnull().sum()}\")\n",
        "print(f\"   dias_atraso - valores nulos: {orders_clean['dias_atraso'].isnull().sum()}\")\n",
        "print(f\"   Valores negativos em dias_para_entrega: {(orders_clean['dias_para_entrega'] < 0).sum()}\")\n",
        "\n",
        "# 2. Distribui√ß√£o das flags de qualidade\n",
        "print(f\"\\n2. DISTRIBUI√á√ÉO DAS FLAGS DE QUALIDADE:\")\n",
        "for flag in ['outlier_tempo_entrega', 'atraso_extremo', 'entrega_muito_rapida']:\n",
        "    count = orders_clean[flag].sum()\n",
        "    pct = count / len(orders_clean) * 100\n",
        "    print(f\"   {flag}: {count:,} ({pct:.1f}%)\")\n",
        "\n",
        "# 3. Verificar integridade dos relacionamentos\n",
        "print(f\"\\n3. INTEGRIDADE DOS RELACIONAMENTOS:\")\n",
        "orders_ids = set(orders_clean['order_id'])\n",
        "reviews_ids = set(reviews_clean['order_id'])\n",
        "items_ids = set(items_clean['order_id'])\n",
        "payments_ids = set(payments_clean['order_id'])\n",
        "\n",
        "print(f\"   Orders √∫nicos: {len(orders_ids):,}\")\n",
        "print(f\"   Intersec√ß√£o orders ‚à© reviews: {len(orders_ids & reviews_ids):,}\")\n",
        "print(f\"   Intersec√ß√£o orders ‚à© items: {len(orders_ids & items_ids):,}\")\n",
        "print(f\"   Intersec√ß√£o orders ‚à© payments: {len(orders_ids & payments_ids):,}\")\n",
        "\n",
        "# 4. Estat√≠sticas finais das features temporais limpas\n",
        "print(f\"\\n4. ESTAT√çSTICAS FINAIS (DADOS LIMPOS):\")\n",
        "print(f\"   Tempo de entrega (dias):\")\n",
        "print(f\"     M√©dia: {orders_clean['dias_para_entrega'].mean():.1f}\")\n",
        "print(f\"     Mediana: {orders_clean['dias_para_entrega'].median():.1f}\")\n",
        "print(f\"     P95: {orders_clean['dias_para_entrega'].quantile(0.95):.1f}\")\n",
        "\n",
        "print(f\"   Atraso (dias):\")\n",
        "print(f\"     M√©dia: {orders_clean['dias_atraso'].mean():.1f}\")\n",
        "print(f\"     % com atraso (>0): {(orders_clean['dias_atraso'] > 0).mean()*100:.1f}%\")\n",
        "\n",
        "print(f\"\\n DADOS VALIDADOS - PRONTOS PARA FEATURE ENGINEERING!\")\n",
        "\n",
        "# 5. Salvar ponto de controle das vari√°veis limpas\n",
        "print(f\"\\n5. SALVANDO PONTO DE CONTROLE...\")\n",
        "print(f\"   Vari√°veis principais atualizadas: orders_clean, reviews_clean, items_clean, payments_clean\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Te70Ra3zgxO-",
        "outputId": "11c016fa-82e4-41c9-8715-5b1bcc48cca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== VALIDA√á√ÉO FINAL DOS DADOS LIMPOS ===\n",
            "1. QUALIDADE DAS FEATURES TEMPORAIS:\n",
            "   dias_para_entrega - valores nulos: 0\n",
            "   dias_atraso - valores nulos: 0\n",
            "   Valores negativos em dias_para_entrega: 0\n",
            "\n",
            "2. DISTRIBUI√á√ÉO DAS FLAGS DE QUALIDADE:\n",
            "   outlier_tempo_entrega: 880 (0.9%)\n",
            "   atraso_extremo: 345 (0.4%)\n",
            "   entrega_muito_rapida: 13 (0.0%)\n",
            "\n",
            "3. INTEGRIDADE DOS RELACIONAMENTOS:\n",
            "   Orders √∫nicos: 96,470\n",
            "   Intersec√ß√£o orders ‚à© reviews: 95,824\n",
            "   Intersec√ß√£o orders ‚à© items: 96,470\n",
            "   Intersec√ß√£o orders ‚à© payments: 96,469\n",
            "\n",
            "4. ESTAT√çSTICAS FINAIS (DADOS LIMPOS):\n",
            "   Tempo de entrega (dias):\n",
            "     M√©dia: 12.1\n",
            "     Mediana: 10.0\n",
            "     P95: 29.0\n",
            "   Atraso (dias):\n",
            "     M√©dia: -11.9\n",
            "     % com atraso (>0): 6.8%\n",
            "\n",
            "‚úÖ DADOS VALIDADOS - PRONTOS PARA FEATURE ENGINEERING!\n",
            "\n",
            "5. SALVANDO PONTO DE CONTROLE...\n",
            "   Vari√°veis principais atualizadas: orders_clean, reviews_clean, items_clean, payments_clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === FEATURE ENGINEERING COMPLETA - ESTRAT√âGIA UNIFICADA ===\n",
        "print(\"=== FEATURE ENGINEERING COMPLETA ===\")\n",
        "print(\"Estrat√©gia: Criar TODAS as features primeiro, depois especializar por problema\")\n",
        "print(\"- Supervisionado: usar features + reviews (excluir pr√≥prio review_score)\")\n",
        "print(\"- Clustering: usar features sem qualquer informa√ß√£o de review\")\n",
        "print()\n",
        "\n",
        "# === PARTE 1: FEATURES AGREGADAS POR PEDIDO (COMPORTAMENTO DE COMPRA) ===\n",
        "print(\"1. CRIANDO FEATURES DE COMPORTAMENTO DE COMPRA POR PEDIDO...\")\n",
        "\n",
        "# 1.1 Agrega√ß√µes dos ITENS por pedido (CORRIGIDA)\n",
        "print(\"   1.1 Agregando dados dos itens...\")\n",
        "\n",
        "# Fun√ß√£o para desvio padr√£o seguro\n",
        "def safe_std(x):\n",
        "    if len(x) <= 1:\n",
        "        return 0.0\n",
        "    return x.std()\n",
        "\n",
        "items_features = items_clean.groupby('order_id').agg({\n",
        "    'order_item_id': 'count',\n",
        "    'product_id': 'nunique',\n",
        "    'seller_id': 'nunique',\n",
        "    'price': ['sum', 'mean', safe_std, 'min', 'max'],\n",
        "    'freight_value': ['sum', 'mean', safe_std]\n",
        "}).round(2)\n",
        "\n",
        "# Simplificar nomes das colunas\n",
        "items_features.columns = [\n",
        "    'qtd_itens', 'qtd_produtos_unicos', 'qtd_vendedores',\n",
        "    'valor_total_produtos', 'valor_medio_item', 'std_valor_item', 'valor_min_item', 'valor_max_item',\n",
        "    'valor_total_frete', 'valor_medio_frete', 'std_valor_frete'\n",
        "]\n",
        "# 1.2 Features derivadas importantes para AMBOS problemas\n",
        "print(\"   1.2 Criando features derivadas relevantes...\")\n",
        "items_features['ticket_medio'] = (items_features['valor_total_produtos'] / items_features['qtd_itens']).round(2)\n",
        "items_features['frete_percentual'] = (items_features['valor_total_frete'] /\n",
        "                                     (items_features['valor_total_produtos'] + items_features['valor_total_frete']) * 100).round(2)\n",
        "items_features['pedido_multi_vendedor'] = (items_features['qtd_vendedores'] > 1).astype(int)\n",
        "items_features['diversidade_produtos'] = (items_features['qtd_produtos_unicos'] / items_features['qtd_itens']).round(2)\n",
        "\n",
        "print(f\"      ‚úì {items_features.shape[0]:,} pedidos com features de itens\")\n",
        "\n",
        "# 1.3 Agrega√ß√µes dos PAGAMENTOS por pedido\n",
        "print(\"   1.3 Agregando dados dos pagamentos...\")\n",
        "payments_features = payments_clean.groupby('order_id').agg({\n",
        "    'payment_sequential': 'count',               # Quantidade de formas de pagamento\n",
        "    'payment_installments': ['sum', 'mean', 'max'], # Estat√≠sticas de parcelas\n",
        "    'payment_value': ['sum', 'mean', 'std']      # Estat√≠sticas de valor pago\n",
        "}).round(2)\n",
        "\n",
        "payments_features.columns = [\n",
        "    'qtd_formas_pagamento',\n",
        "    'total_parcelas', 'media_parcelas', 'max_parcelas',\n",
        "    'valor_total_pago', 'valor_medio_pagamento', 'std_valor_pagamento'\n",
        "]\n",
        "\n",
        "print(f\"      ‚úì {payments_features.shape[0]:,} pedidos com features de pagamento\")\n",
        "\n",
        "# 1.4 Tipos de pagamento (importantes para segmenta√ß√£o)\n",
        "print(\"   1.4 Criando features de tipos de pagamento...\")\n",
        "payment_types = payments_clean.groupby('order_id')['payment_type'].apply(list).reset_index()\n",
        "payment_types['usa_credit_card'] = payment_types['payment_type'].apply(lambda x: 1 if 'credit_card' in x else 0)\n",
        "payment_types['usa_boleto'] = payment_types['payment_type'].apply(lambda x: 1 if 'boleto' in x else 0)\n",
        "payment_types['usa_debit_card'] = payment_types['payment_type'].apply(lambda x: 1 if 'debit_card' in x else 0)\n",
        "payment_types['usa_voucher'] = payment_types['payment_type'].apply(lambda x: 1 if 'voucher' in x else 0)\n",
        "payment_types['diversidade_pagamento'] = payment_types['payment_type'].apply(lambda x: len(set(x)))\n",
        "payment_types = payment_types.drop('payment_type', axis=1).set_index('order_id')\n",
        "\n",
        "print(f\"      ‚úì Features de tipos de pagamento criadas\")\n",
        "\n",
        "print(f\"\\n RESUMO PARTE 1:\")\n",
        "print(f\"   Items features: {items_features.shape}\")\n",
        "print(f\"   Payments features: {payments_features.shape}\")\n",
        "print(f\"   Payment types: {payment_types.shape}\")\n",
        "print(f\" Features de comportamento de compra criadas!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKLTodD9hh2P",
        "outputId": "ad33ec2a-b0be-46ff-df63-6cce5b7599ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== FEATURE ENGINEERING COMPLETA ===\n",
            "Estrat√©gia: Criar TODAS as features primeiro, depois especializar por problema\n",
            "- Supervisionado: usar features + reviews (excluir pr√≥prio review_score)\n",
            "- Clustering: usar features sem qualquer informa√ß√£o de review\n",
            "\n",
            "1. CRIANDO FEATURES DE COMPORTAMENTO DE COMPRA POR PEDIDO...\n",
            "   1.1 Agregando dados dos itens...\n",
            "   1.2 Criando features derivadas relevantes...\n",
            "      ‚úì 96,470 pedidos com features de itens\n",
            "   1.3 Agregando dados dos pagamentos...\n",
            "      ‚úì 96,469 pedidos com features de pagamento\n",
            "   1.4 Criando features de tipos de pagamento...\n",
            "      ‚úì Features de tipos de pagamento criadas\n",
            "\n",
            " RESUMO PARTE 1:\n",
            "   Items features: (96470, 15)\n",
            "   Payments features: (96469, 7)\n",
            "   Payment types: (96469, 5)\n",
            " Features de comportamento de compra criadas!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === PARTE 2: FEATURES DE COMPORTAMENTO HIST√ìRICO DO CLIENTE (CORRIGIDA) ===\n",
        "print(\"2. CRIANDO FEATURES DE COMPORTAMENTO HIST√ìRICO DO CLIENTE...\")\n",
        "print(\"   CORRE√á√ÉO: Usando customer_unique_id para capturar recorr√™ncia real\")\n",
        "\n",
        "# 2.1 Merge para obter customer_unique_id correto\n",
        "print(\"   2.1 Preparando dados com identifica√ß√£o correta de clientes...\")\n",
        "orders_with_unique = orders_clean.merge(\n",
        "    customers[['customer_id', 'customer_unique_id']],\n",
        "    on='customer_id', how='left'\n",
        ")\n",
        "\n",
        "orders_temporal = orders_with_unique[['order_id', 'customer_unique_id', 'order_purchase_timestamp']].copy()\n",
        "orders_temporal = orders_temporal.sort_values(['customer_unique_id', 'order_purchase_timestamp'])\n",
        "\n",
        "# 2.2 Calcular features de rec√™ncia e frequ√™ncia por cliente REAL\n",
        "print(\"   2.2 Calculando features de rec√™ncia e frequ√™ncia...\")\n",
        "customer_behavior = orders_temporal.groupby('customer_unique_id').agg({\n",
        "    'order_id': 'count',                        # Total de pedidos do cliente\n",
        "    'order_purchase_timestamp': ['min', 'max']  # Primeira e √∫ltima compra\n",
        "}).round(2)\n",
        "\n",
        "customer_behavior.columns = ['total_pedidos_cliente', 'primeira_compra', 'ultima_compra']\n",
        "\n",
        "# 2.3 Calcular tempo como cliente e frequ√™ncia de compra\n",
        "print(\"   2.3 Calculando tempo como cliente e frequ√™ncia...\")\n",
        "customer_behavior['dias_como_cliente'] = (\n",
        "    customer_behavior['ultima_compra'] - customer_behavior['primeira_compra']\n",
        ").dt.days.fillna(0)\n",
        "\n",
        "# Frequ√™ncia de compra (pedidos por m√™s)\n",
        "customer_behavior['frequencia_compra_mensal'] = (\n",
        "    customer_behavior['total_pedidos_cliente'] /\n",
        "    (customer_behavior['dias_como_cliente'] / 30 + 1)  # +1 para evitar divis√£o por zero\n",
        ").round(3)\n",
        "\n",
        "# 2.4 Classificar tipos de cliente\n",
        "print(\"   2.4 Classificando tipos de cliente...\")\n",
        "customer_behavior['cliente_recorrente'] = (customer_behavior['total_pedidos_cliente'] > 1).astype(int)\n",
        "customer_behavior['cliente_frequente'] = (customer_behavior['total_pedidos_cliente'] >= 3).astype(int)\n",
        "\n",
        "# 2.5 Para cada pedido, calcular posi√ß√£o na jornada do cliente\n",
        "print(\"   2.5 Calculando posi√ß√£o na jornada do cliente...\")\n",
        "orders_temporal['pedido_numero'] = orders_temporal.groupby('customer_unique_id').cumcount() + 1\n",
        "orders_temporal['is_primeiro_pedido'] = (orders_temporal['pedido_numero'] == 1).astype(int)\n",
        "\n",
        "# Merge com dados do cliente\n",
        "customer_features = orders_temporal[['order_id', 'customer_unique_id', 'pedido_numero', 'is_primeiro_pedido']].merge(\n",
        "    customer_behavior[['total_pedidos_cliente', 'frequencia_compra_mensal', 'cliente_recorrente', 'cliente_frequente']],\n",
        "    left_on='customer_unique_id', right_index=True\n",
        ").set_index('order_id')\n",
        "\n",
        "print(f\"   Resultado: {customer_features.shape[0]:,} pedidos com features de cliente\")\n",
        "\n",
        "# 2.6 Estat√≠sticas de comportamento do cliente CORRETAS\n",
        "print(f\"\\n   ESTATISTICAS DE COMPORTAMENTO (CORRIGIDAS):\")\n",
        "print(f\"   Clientes √∫nicos reais: {customer_behavior.shape[0]:,}\")\n",
        "print(f\"   Clientes recorrentes: {customer_behavior['cliente_recorrente'].sum():,} ({customer_behavior['cliente_recorrente'].mean()*100:.1f}%)\")\n",
        "print(f\"   Clientes frequentes (3+): {customer_behavior['cliente_frequente'].sum():,} ({customer_behavior['cliente_frequente'].mean()*100:.1f}%)\")\n",
        "print(f\"   Pedidos m√©dios por cliente: {customer_behavior['total_pedidos_cliente'].mean():.2f}\")\n",
        "print(f\"   M√°ximo de pedidos por cliente: {customer_behavior['total_pedidos_cliente'].max()}\")\n",
        "\n",
        "# Distribui√ß√£o correta\n",
        "print(f\"\\n   DISTRIBUI√á√ÉO DE PEDIDOS POR CLIENTE:\")\n",
        "dist = customer_behavior['total_pedidos_cliente'].value_counts().sort_index()\n",
        "for pedidos, count in dist.head(8).items():\n",
        "    pct = count / len(customer_behavior) * 100\n",
        "    print(f\"     {pedidos} pedido(s): {count:,} clientes ({pct:.1f}%)\")\n",
        "\n",
        "# IMPORTANTE: Definir customer_features para uso posterior\n",
        "customer_features = customer_features_corrected.copy()\n",
        "print(f\"‚úì customer_features definido: {customer_features.shape}\")\n",
        "\n",
        "print(f\"\\n RESUMO PARTE 2 (CORRIGIDA):\")\n",
        "print(f\"   Customer features: {customer_features.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgWrzdLHhsqy",
        "outputId": "603686c1-fca3-4410-9c13-569ae4ff0704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2. CRIANDO FEATURES DE COMPORTAMENTO HIST√ìRICO DO CLIENTE...\n",
            "   CORRE√á√ÉO: Usando customer_unique_id para capturar recorr√™ncia real\n",
            "   2.1 Preparando dados com identifica√ß√£o correta de clientes...\n",
            "   2.2 Calculando features de rec√™ncia e frequ√™ncia...\n",
            "   2.3 Calculando tempo como cliente e frequ√™ncia...\n",
            "   2.4 Classificando tipos de cliente...\n",
            "   2.5 Calculando posi√ß√£o na jornada do cliente...\n",
            "   Resultado: 96,470 pedidos com features de cliente\n",
            "\n",
            "   ESTATISTICAS DE COMPORTAMENTO (CORRIGIDAS):\n",
            "   Clientes √∫nicos reais: 93,350\n",
            "   Clientes recorrentes: 2,801 (3.0%)\n",
            "   Clientes frequentes (3+): 228 (0.2%)\n",
            "   Pedidos m√©dios por cliente: 1.03\n",
            "   M√°ximo de pedidos por cliente: 15\n",
            "\n",
            "   DISTRIBUI√á√ÉO DE PEDIDOS POR CLIENTE:\n",
            "     1 pedido(s): 90,549 clientes (97.0%)\n",
            "     2 pedido(s): 2,573 clientes (2.8%)\n",
            "     3 pedido(s): 181 clientes (0.2%)\n",
            "     4 pedido(s): 28 clientes (0.0%)\n",
            "     5 pedido(s): 9 clientes (0.0%)\n",
            "     6 pedido(s): 5 clientes (0.0%)\n",
            "     7 pedido(s): 3 clientes (0.0%)\n",
            "     9 pedido(s): 1 clientes (0.0%)\n",
            "\n",
            " RESUMO PARTE 2 (CORRIGIDA):\n",
            "   Customer features: (96470, 7)\n",
            " Features de comportamento do cliente criadas corretamente!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === INVESTIGA√á√ÉO: VERIFICA√á√ÉO DE RECORR√äNCIA DE CLIENTES ===\n",
        "print(\"=== INVESTIGANDO RECORR√äNCIA DE CLIENTES ===\")\n",
        "print(\"Verificando se a baixa recorr√™ncia √© real ou artefato da limpeza\")\n",
        "\n",
        "# 1. Verificar nos dados ORIGINAIS (antes da limpeza)\n",
        "print(\"1. AN√ÅLISE DOS DADOS ORIGINAIS (antes da limpeza):\")\n",
        "original_customers = orders.groupby('customer_id').agg({\n",
        "    'order_id': 'count',\n",
        "    'order_status': lambda x: list(x.unique())\n",
        "}).rename(columns={'order_id': 'total_pedidos'})\n",
        "\n",
        "print(f\"   Clientes √∫nicos (dados originais): {len(original_customers):,}\")\n",
        "print(f\"   Distribui√ß√£o de pedidos por cliente (original):\")\n",
        "recurrence_dist = original_customers['total_pedidos'].value_counts().sort_index()\n",
        "for pedidos, count in recurrence_dist.head(10).items():\n",
        "    pct = count / len(original_customers) * 100\n",
        "    print(f\"     {pedidos} pedido(s): {count:,} clientes ({pct:.1f}%)\")\n",
        "\n",
        "# 2. Verificar customer_unique_id vs customer_id\n",
        "print(f\"\\n2. VERIFICA√á√ÉO DE IDs DE CLIENTE:\")\n",
        "print(f\"   customer_id √∫nicos: {customers['customer_id'].nunique():,}\")\n",
        "print(f\"   customer_unique_id √∫nicos: {customers['customer_unique_id'].nunique():,}\")\n",
        "print(f\"   Diferen√ßa: {customers['customer_id'].nunique() - customers['customer_unique_id'].nunique():,}\")\n",
        "\n",
        "# 3. Analisar se customer_unique_id mostra padr√£o diferente\n",
        "print(f\"\\n3. AN√ÅLISE POR CUSTOMER_UNIQUE_ID:\")\n",
        "orders_with_unique = orders.merge(customers[['customer_id', 'customer_unique_id']], on='customer_id')\n",
        "unique_customers = orders_with_unique.groupby('customer_unique_id').agg({\n",
        "    'order_id': 'count',\n",
        "    'customer_id': 'nunique'  # Quantos customer_id diferentes para cada unique_id\n",
        "}).rename(columns={'order_id': 'total_pedidos', 'customer_id': 'ids_diferentes'})\n",
        "\n",
        "print(f\"   Clientes √∫nicos (por unique_id): {len(unique_customers):,}\")\n",
        "print(f\"   Distribui√ß√£o por customer_unique_id:\")\n",
        "unique_recurrence = unique_customers['total_pedidos'].value_counts().sort_index()\n",
        "for pedidos, count in unique_recurrence.head(10).items():\n",
        "    pct = count / len(unique_customers) * 100\n",
        "    print(f\"     {pedidos} pedido(s): {count:,} clientes ({pct:.1f}%)\")\n",
        "\n",
        "# 4. Verificar se nossa limpeza afetou a recorr√™ncia\n",
        "print(f\"\\n4. IMPACTO DA LIMPEZA NA RECORR√äNCIA:\")\n",
        "clean_customers = orders_clean.groupby('customer_id')['order_id'].count()\n",
        "print(f\"   Clientes ap√≥s limpeza: {len(clean_customers):,}\")\n",
        "print(f\"   Clientes com >1 pedido (ap√≥s limpeza): {(clean_customers > 1).sum():,}\")\n",
        "\n",
        "# 5. Comparar customer_id que aparecem nos dados originais vs limpos\n",
        "original_customer_ids = set(orders['customer_id'])\n",
        "clean_customer_ids = set(orders_clean['customer_id'])\n",
        "lost_customers = len(original_customer_ids - clean_customer_ids)\n",
        "print(f\"   Customer_ids perdidos na limpeza: {lost_customers:,}\")\n",
        "\n",
        "print(f\"\\nCONCLUS√ÉO DA INVESTIGA√á√ÉO:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C18qqlKCiEZm",
        "outputId": "4275ceaa-8477-46c7-9ab5-ba78f1a6208c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== INVESTIGANDO RECORR√äNCIA DE CLIENTES ===\n",
            "Verificando se a baixa recorr√™ncia √© real ou artefato da limpeza\n",
            "1. AN√ÅLISE DOS DADOS ORIGINAIS (antes da limpeza):\n",
            "   Clientes √∫nicos (dados originais): 99,441\n",
            "   Distribui√ß√£o de pedidos por cliente (original):\n",
            "     1 pedido(s): 99,441 clientes (100.0%)\n",
            "\n",
            "2. VERIFICA√á√ÉO DE IDs DE CLIENTE:\n",
            "   customer_id √∫nicos: 99,441\n",
            "   customer_unique_id √∫nicos: 96,096\n",
            "   Diferen√ßa: 3,345\n",
            "\n",
            "3. AN√ÅLISE POR CUSTOMER_UNIQUE_ID:\n",
            "   Clientes √∫nicos (por unique_id): 96,096\n",
            "   Distribui√ß√£o por customer_unique_id:\n",
            "     1 pedido(s): 93,099 clientes (96.9%)\n",
            "     2 pedido(s): 2,745 clientes (2.9%)\n",
            "     3 pedido(s): 203 clientes (0.2%)\n",
            "     4 pedido(s): 30 clientes (0.0%)\n",
            "     5 pedido(s): 8 clientes (0.0%)\n",
            "     6 pedido(s): 6 clientes (0.0%)\n",
            "     7 pedido(s): 3 clientes (0.0%)\n",
            "     9 pedido(s): 1 clientes (0.0%)\n",
            "     17 pedido(s): 1 clientes (0.0%)\n",
            "\n",
            "4. IMPACTO DA LIMPEZA NA RECORR√äNCIA:\n",
            "   Clientes ap√≥s limpeza: 96,470\n",
            "   Clientes com >1 pedido (ap√≥s limpeza): 0\n",
            "   Customer_ids perdidos na limpeza: 2,971\n",
            "\n",
            "CONCLUS√ÉO DA INVESTIGA√á√ÉO:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CONCLUS√ÉO DA INVESTIGA√á√ÉO E CORRE√á√ÉO ===\n",
        "print(\"=== CONCLUS√ÉO DA INVESTIGA√á√ÉO ===\")\n",
        "print(\"DESCOBERTAS IMPORTANTES:\")\n",
        "print(\"1. Cada 'customer_id' realmente tem apenas 1 pedido (100%)\")\n",
        "print(\"2. MAS: customer_unique_id mostra o padr√£o REAL de recorr√™ncia:\")\n",
        "print(\"   - 96.9% clientes com 1 pedido\")\n",
        "print(\"   - 2.9% clientes com 2 pedidos\")\n",
        "print(\"   - 0.2% clientes com 3+ pedidos\")\n",
        "print(\"3. Nossa limpeza eliminou justamente os pedidos recorrentes!\")\n",
        "print(\"   (provavelmente pedidos shipped/canceled de clientes recorrentes)\")\n",
        "\n",
        "print(\"\\nIMPLICA√á√ÉO PARA FEATURE ENGINEERING:\")\n",
        "print(\"- customer_id = identificador √∫nico por pedido\")\n",
        "print(\"- customer_unique_id = identificador real do cliente\")\n",
        "print(\"- Precisamos REFAZER features de cliente usando customer_unique_id\")\n",
        "\n",
        "print(\"\\n=== CORRIGINDO FEATURES DE COMPORTAMENTO DO CLIENTE ===\")\n",
        "\n",
        "# CORRE√á√ÉO: Usar customer_unique_id para calcular recorr√™ncia real\n",
        "print(\"1. Recalculando com customer_unique_id...\")\n",
        "\n",
        "# Merge para obter customer_unique_id nos pedidos limpos\n",
        "orders_corrected = orders_clean.merge(\n",
        "    customers[['customer_id', 'customer_unique_id']],\n",
        "    on='customer_id', how='left'\n",
        ")\n",
        "\n",
        "# Recalcular comportamento por customer_unique_id\n",
        "customer_behavior_corrected = orders_corrected.groupby('customer_unique_id').agg({\n",
        "    'order_id': 'count',\n",
        "    'order_purchase_timestamp': ['min', 'max']\n",
        "}).round(2)\n",
        "\n",
        "customer_behavior_corrected.columns = ['total_pedidos_cliente', 'primeira_compra', 'ultima_compra']\n",
        "\n",
        "# Tempo como cliente e frequ√™ncia\n",
        "customer_behavior_corrected['dias_como_cliente'] = (\n",
        "    customer_behavior_corrected['ultima_compra'] - customer_behavior_corrected['primeira_compra']\n",
        ").dt.days.fillna(0)\n",
        "\n",
        "customer_behavior_corrected['frequencia_compra_mensal'] = (\n",
        "    customer_behavior_corrected['total_pedidos_cliente'] /\n",
        "    (customer_behavior_corrected['dias_como_cliente'] / 30 + 1)\n",
        ").round(3)\n",
        "\n",
        "# Classifica√ß√µes corrigidas\n",
        "customer_behavior_corrected['cliente_recorrente'] = (customer_behavior_corrected['total_pedidos_cliente'] > 1).astype(int)\n",
        "customer_behavior_corrected['cliente_frequente'] = (customer_behavior_corrected['total_pedidos_cliente'] >= 3).astype(int)\n",
        "\n",
        "# Mapear de volta para os pedidos\n",
        "customer_features_corrected = orders_corrected[['order_id', 'customer_unique_id']].merge(\n",
        "    customer_behavior_corrected[['total_pedidos_cliente', 'cliente_recorrente', 'frequencia_compra_mensal']],\n",
        "    left_on='customer_unique_id', right_index=True\n",
        ").set_index('order_id')\n",
        "\n",
        "print(f\"2. ESTAT√çSTICAS CORRIGIDAS:\")\n",
        "print(f\"   Clientes √∫nicos reais: {customer_behavior_corrected.shape[0]:,}\")\n",
        "print(f\"   Clientes recorrentes: {customer_behavior_corrected['cliente_recorrente'].sum():,} ({customer_behavior_corrected['cliente_recorrente'].mean()*100:.1f}%)\")\n",
        "print(f\"   Pedidos m√©dios por cliente: {customer_behavior_corrected['total_pedidos_cliente'].mean():.2f}\")\n",
        "print(f\"   Max pedidos por cliente: {customer_behavior_corrected['total_pedidos_cliente'].max()}\")\n",
        "\n",
        "print(f\"\\n3. DISTRIBUI√á√ÉO CORRIGIDA DE PEDIDOS POR CLIENTE:\")\n",
        "dist_corrected = customer_behavior_corrected['total_pedidos_cliente'].value_counts().sort_index()\n",
        "for pedidos, count in dist_corrected.head(8).items():\n",
        "    pct = count / len(customer_behavior_corrected) * 100\n",
        "    print(f\"   {pedidos} pedido(s): {count:,} clientes ({pct:.1f}%)\")\n",
        "\n",
        "print(f\"\\nATUALIZA√á√ÉO CONCLU√çDA:\")\n",
        "print(f\"   Features de cliente corrigidas: {customer_features_corrected.shape}\")\n",
        "print(\"   Agora refletem o comportamento real de recorr√™ncia!\")"
      ],
      "metadata": {
        "id": "afd0eVasiXMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === PARTE 3: FEATURES DE PRODUTOS E VENDEDORES ===\n",
        "print(\"3. CRIANDO FEATURES DE PRODUTOS E VENDEDORES...\")\n",
        "print(\"   Objetivo: Capturar qualidade, popularidade e performance\")\n",
        "\n",
        "# 3.1 Features de produtos - popularidade e caracter√≠sticas\n",
        "print(\"   3.1 Calculando features de produtos...\")\n",
        "\n",
        "# Popularidade dos produtos (quantas vezes foram vendidos)\n",
        "product_popularity = items_clean.groupby('product_id').agg({\n",
        "    'order_id': 'nunique',                   # Quantos pedidos √∫nicos\n",
        "    'order_item_id': 'count',                # Quantos itens vendidos total\n",
        "    'price': ['mean', 'std'],                # Pre√ßo m√©dio e varia√ß√£o\n",
        "    'freight_value': 'mean'                  # Frete m√©dio\n",
        "}).round(2)\n",
        "\n",
        "product_popularity.columns = [\n",
        "    'produto_qtd_pedidos', 'produto_qtd_vendas',\n",
        "    'produto_preco_medio', 'produto_std_preco', 'produto_frete_medio'\n",
        "]\n",
        "\n",
        "# Classificar produtos por popularidade\n",
        "product_popularity['produto_popular'] = (\n",
        "    product_popularity['produto_qtd_pedidos'] >=\n",
        "    product_popularity['produto_qtd_pedidos'].quantile(0.8)\n",
        ").astype(int)\n",
        "\n",
        "print(f\"      Produtos √∫nicos analisados: {product_popularity.shape[0]:,}\")\n",
        "\n",
        "# 3.2 Features de vendedores - performance e volume\n",
        "print(\"   3.2 Calculando features de vendedores...\")\n",
        "\n",
        "# Performance dos vendedores\n",
        "seller_performance = items_clean.groupby('seller_id').agg({\n",
        "    'order_id': 'nunique',                   # Quantos pedidos √∫nicos\n",
        "    'product_id': 'nunique',                 # Diversidade de produtos\n",
        "    'price': ['sum', 'mean'],                # Volume e ticket m√©dio\n",
        "    'freight_value': 'mean'                  # Frete m√©dio cobrado\n",
        "}).round(2)\n",
        "\n",
        "seller_performance.columns = [\n",
        "    'vendedor_qtd_pedidos', 'vendedor_diversidade_produtos',\n",
        "    'vendedor_volume_vendas', 'vendedor_ticket_medio', 'vendedor_frete_medio'\n",
        "]\n",
        "\n",
        "# Classificar vendedores por volume\n",
        "seller_performance['vendedor_alto_volume'] = (\n",
        "    seller_performance['vendedor_qtd_pedidos'] >=\n",
        "    seller_performance['vendedor_qtd_pedidos'].quantile(0.9)\n",
        ").astype(int)\n",
        "\n",
        "print(f\"      Vendedores √∫nicos analisados: {seller_performance.shape[0]:,}\")\n",
        "\n",
        "# 3.3 Mapear features de volta para os pedidos\n",
        "print(\"   3.3 Mapeando features para os pedidos...\")\n",
        "\n",
        "# Para pedidos com m√∫ltiplos itens/vendedores, vamos agregar\n",
        "items_with_features = items_clean.merge(\n",
        "    product_popularity, left_on='product_id', right_index=True, how='left'\n",
        ").merge(\n",
        "    seller_performance, left_on='seller_id', right_index=True, how='left'\n",
        ")\n",
        "\n",
        "# Agregar por pedido (m√©dia para m√∫ltiplos itens)\n",
        "product_seller_features = items_with_features.groupby('order_id').agg({\n",
        "    'produto_qtd_pedidos': 'mean',\n",
        "    'produto_preco_medio': 'mean',\n",
        "    'produto_popular': 'max',                # Se pelo menos 1 produto popular\n",
        "    'vendedor_qtd_pedidos': 'mean',\n",
        "    'vendedor_ticket_medio': 'mean',\n",
        "    'vendedor_alto_volume': 'max',           # Se pelo menos 1 vendedor alto volume\n",
        "    'vendedor_diversidade_produtos': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "print(f\"      Pedidos com features de produto/vendedor: {product_seller_features.shape[0]:,}\")\n",
        "\n",
        "# 3.4 Estat√≠sticas dos produtos e vendedores\n",
        "print(f\"\\n   ESTATISTICAS DE PRODUTOS E VENDEDORES:\")\n",
        "print(f\"   Produtos populares (top 20%): {product_popularity['produto_popular'].sum():,}\")\n",
        "print(f\"   Vendedores alto volume (top 10%): {seller_performance['vendedor_alto_volume'].sum():,}\")\n",
        "print(f\"   Pedidos com produto popular: {product_seller_features['produto_popular'].sum():,}\")\n",
        "print(f\"   Pedidos com vendedor alto volume: {product_seller_features['vendedor_alto_volume'].sum():,}\")\n",
        "\n",
        "print(f\"\\n RESUMO PARTE 3:\")\n",
        "print(f\"   Product/Seller features: {product_seller_features.shape}\")\n",
        "print(f\" Features de produtos e vendedores criadas!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9eF_q2pi3Fq",
        "outputId": "b79b410e-087e-446e-916f-8767bb531b01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3. CRIANDO FEATURES DE PRODUTOS E VENDEDORES...\n",
            "   Objetivo: Capturar qualidade, popularidade e performance\n",
            "   3.1 Calculando features de produtos...\n",
            "      Produtos √∫nicos analisados: 32,214\n",
            "   3.2 Calculando features de vendedores...\n",
            "      Vendedores √∫nicos analisados: 2,970\n",
            "   3.3 Mapeando features para os pedidos...\n",
            "      Pedidos com features de produto/vendedor: 96,470\n",
            "\n",
            "   ESTATISTICAS DE PRODUTOS E VENDEDORES:\n",
            "   Produtos populares (top 20%): 7,776\n",
            "   Vendedores alto volume (top 10%): 299\n",
            "   Pedidos com produto popular: 68,729\n",
            "   Pedidos com vendedor alto volume: 65,863\n",
            "\n",
            " RESUMO PARTE 3:\n",
            "   Product/Seller features: (96470, 7)\n",
            " Features de produtos e vendedores criadas!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === PARTE 4: FEATURES GEOGR√ÅFICAS E CONSOLIDA√á√ÉO FINAL ===\n",
        "print(\"4. CRIANDO FEATURES GEOGR√ÅFICAS E CONSOLIDANDO DATASET...\")\n",
        "\n",
        "# 4.1 Features geogr√°ficas b√°sicas\n",
        "print(\"   4.1 Criando features geogr√°ficas...\")\n",
        "\n",
        "# Mapear estados de clientes e vendedores para os pedidos\n",
        "customer_geo = customers[['customer_id', 'customer_state', 'customer_city']].rename(columns={\n",
        "    'customer_state': 'cliente_estado',\n",
        "    'customer_city': 'cliente_cidade'\n",
        "})\n",
        "\n",
        "# Para vendedores, vamos pegar o estado predominante por pedido\n",
        "seller_geo = items_clean.merge(\n",
        "    sellers[['seller_id', 'seller_state', 'seller_city']],\n",
        "    on='seller_id', how='left'\n",
        ").groupby('order_id').agg({\n",
        "    'seller_state': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0],  # Estado mais comum\n",
        "    'seller_city': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0]    # Cidade mais comum\n",
        "}).rename(columns={\n",
        "    'seller_state': 'vendedor_estado',\n",
        "    'seller_city': 'vendedor_cidade'\n",
        "})\n",
        "\n",
        "# Features geogr√°ficas derivadas\n",
        "geo_features = orders_clean[['order_id', 'customer_id']].merge(\n",
        "    customer_geo, on='customer_id', how='left'\n",
        ").merge(\n",
        "    seller_geo, left_on='order_id', right_index=True, how='left'\n",
        ").set_index('order_id')\n",
        "\n",
        "# Criar flag para entrega no mesmo estado\n",
        "geo_features['mesmo_estado'] = (geo_features['cliente_estado'] == geo_features['vendedor_estado']).astype(int)\n",
        "\n",
        "# Estados com maior volume (para criar features)\n",
        "top_customer_states = geo_features['cliente_estado'].value_counts().head(5).index\n",
        "top_seller_states = geo_features['vendedor_estado'].value_counts().head(5).index\n",
        "\n",
        "for state in top_customer_states:\n",
        "    geo_features[f'cliente_estado_{state}'] = (geo_features['cliente_estado'] == state).astype(int)\n",
        "\n",
        "print(f\"      Features geogr√°ficas criadas: {geo_features.shape}\")\n",
        "\n",
        "# 4.2 CONSOLIDA√á√ÉO FINAL - MERGE DE TODAS AS FEATURES\n",
        "print(\"   4.2 Consolidando todas as features em dataset √∫nico...\")\n",
        "\n",
        "# Come√ßar com orders_clean como base\n",
        "dataset_final = orders_clean.set_index('order_id')\n",
        "\n",
        "# Adicionar todas as features criadas\n",
        "print(\"      Adicionando features de itens...\")\n",
        "dataset_final = dataset_final.join(items_features, how='left')\n",
        "\n",
        "print(\"      Adicionando features de pagamentos...\")\n",
        "dataset_final = dataset_final.join(payments_features, how='left')\n",
        "dataset_final = dataset_final.join(payment_types, how='left')\n",
        "\n",
        "print(\"      Adicionando features de clientes...\")\n",
        "dataset_final = dataset_final.join(customer_features, how='left')\n",
        "\n",
        "print(\"      Adicionando features de produtos/vendedores...\")\n",
        "dataset_final = dataset_final.join(product_seller_features, how='left')\n",
        "\n",
        "print(\"      Adicionando features geogr√°ficas...\")\n",
        "dataset_final = dataset_final.join(geo_features.drop(['customer_id'], axis=1), how='left')\n",
        "\n",
        "# 4.3 VERIFICA√á√ÉO FINAL DO DATASET\n",
        "print(f\"\\n   4.3 VERIFICA√á√ÉO DO DATASET CONSOLIDADO:\")\n",
        "print(f\"      Shape final: {dataset_final.shape}\")\n",
        "print(f\"      Colunas criadas: {dataset_final.shape[1] - 17}\")  # 17 = colunas originais + temporais\n",
        "print(f\"      Valores nulos por coluna:\")\n",
        "\n",
        "# Mostrar colunas com valores nulos\n",
        "null_counts = dataset_final.isnull().sum()\n",
        "null_cols = null_counts[null_counts > 0]\n",
        "if len(null_cols) > 0:\n",
        "    for col, count in null_cols.items():\n",
        "        pct = count / len(dataset_final) * 100\n",
        "        print(f\"        {col}: {count:,} ({pct:.1f}%)\")\n",
        "else:\n",
        "    print(\"        Nenhum valor nulo encontrado!\")\n",
        "\n",
        "print(f\"\\n CONSOLIDA√á√ÉO CONCLU√çDA:\")\n",
        "print(f\"   Dataset final: {dataset_final.shape}\")\n",
        "print(f\" Todas as features criadas e consolidadas com sucesso!\")\n",
        "\n",
        "# 4.4 Salvar resumo das features criadas\n",
        "print(f\"\\n   4.4 RESUMO DAS CATEGORIAS DE FEATURES:\")\n",
        "feature_categories = {\n",
        "    'Temporais': ['dias_para_entrega', 'dias_atraso', 'purchase_month', 'purchase_weekday', 'purchase_hour'],\n",
        "    'Itens/Compra': ['qtd_itens', 'valor_total_produtos', 'ticket_medio', 'frete_percentual'],\n",
        "    'Pagamento': ['qtd_formas_pagamento', 'media_parcelas', 'usa_credit_card', 'usa_boleto'],\n",
        "    'Cliente': ['total_pedidos_cliente', 'cliente_recorrente', 'is_primeiro_pedido'],\n",
        "    'Produto/Vendedor': ['produto_popular', 'vendedor_alto_volume', 'produto_preco_medio'],\n",
        "    'Geogr√°ficas': ['mesmo_estado', 'cliente_estado_SP', 'cliente_estado_RJ']\n",
        "}\n",
        "\n",
        "for category, features in feature_categories.items():\n",
        "    available = [f for f in features if f in dataset_final.columns]\n",
        "    print(f\"      {category}: {len(available)} features\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grHoHUUtjEXW",
        "outputId": "b5efb2d3-fe8a-42d1-cb83-3b214fdf8865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4. CRIANDO FEATURES GEOGR√ÅFICAS E CONSOLIDANDO DATASET...\n",
            "   4.1 Criando features geogr√°ficas...\n",
            "      Features geogr√°ficas criadas: (96470, 11)\n",
            "   4.2 Consolidando todas as features em dataset √∫nico...\n",
            "      Adicionando features de itens...\n",
            "      Adicionando features de pagamentos...\n",
            "      Adicionando features de clientes...\n",
            "      Adicionando features de produtos/vendedores...\n",
            "      Adicionando features geogr√°ficas...\n",
            "\n",
            "   4.3 VERIFICA√á√ÉO DO DATASET CONSOLIDADO:\n",
            "      Shape final: (96470, 70)\n",
            "      Colunas criadas: 53\n",
            "      Valores nulos por coluna:\n",
            "        order_approved_at: 14 (0.0%)\n",
            "        order_delivered_carrier_date: 1 (0.0%)\n",
            "        std_valor_item: 86,835 (90.0%)\n",
            "        std_valor_frete: 86,835 (90.0%)\n",
            "        qtd_formas_pagamento: 1 (0.0%)\n",
            "        total_parcelas: 1 (0.0%)\n",
            "        media_parcelas: 1 (0.0%)\n",
            "        max_parcelas: 1 (0.0%)\n",
            "        valor_total_pago: 1 (0.0%)\n",
            "        valor_medio_pagamento: 1 (0.0%)\n",
            "        std_valor_pagamento: 93,595 (97.0%)\n",
            "        usa_credit_card: 1 (0.0%)\n",
            "        usa_boleto: 1 (0.0%)\n",
            "        usa_debit_card: 1 (0.0%)\n",
            "        usa_voucher: 1 (0.0%)\n",
            "        diversidade_pagamento: 1 (0.0%)\n",
            "\n",
            " CONSOLIDA√á√ÉO CONCLU√çDA:\n",
            "   Dataset final: (96470, 70)\n",
            " Todas as features criadas e consolidadas com sucesso!\n",
            "\n",
            "   4.4 RESUMO DAS CATEGORIAS DE FEATURES:\n",
            "      Temporais: 5 features\n",
            "      Itens/Compra: 4 features\n",
            "      Pagamento: 4 features\n",
            "      Cliente: 3 features\n",
            "      Produto/Vendedor: 3 features\n",
            "      Geogr√°ficas: 3 features\n"
          ]
        }
      ]
    }
  ]
}